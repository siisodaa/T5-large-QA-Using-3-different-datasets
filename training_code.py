# -*- coding: utf-8 -*-
"""Training Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qtvdOJSaAQZooQzhS6qkOmmCxW58jgyM
"""

import pandas as pd
import json
import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq, TrainerCallback
from datasets import load_dataset, load_metric
import os
import shutil
from tqdm import tqdm

# Tokenizer initialization
model_name = "t5-large"
tokenizer = T5Tokenizer.from_pretrained(model_name)

# Preprocess function
def preprocess_data(examples):
    context = examples['context'][0] if 'context' in examples else ""
    questions = examples['question'] if 'question' in examples else ""
    answers = [examples['answer']] if 'answer' in examples else []

    input_texts = [f"question: {q} context: {context}" for q in questions]
    target_texts = answers

    model_inputs = tokenizer(input_texts, max_length=512, truncation=True, padding="max_length")
    labels = tokenizer(target_texts, max_length=128, truncation=True, padding="max_length").input_ids

    model_inputs["labels"] = labels
    return model_inputs

# Custom callback for model saving based on evaluation
class SaveBestModelCallback(TrainerCallback):
    def __init__(self, eval_dataset, tokenizer, model, device, patience=3):
        self.eval_dataset = eval_dataset
        self.tokenizer = tokenizer
        self.model = model
        self.device = device
        self.best_score = 0.0
        self.best_model_dir = 'best_model'
        self.no_improvement_epochs = 0
        self.previous_score = 0.0
        self.patience = patience

    def on_epoch_end(self, args, state, control, **kwargs):
        # Prepare data for evaluation
        predictions = []
        references = []
        for example in tqdm(self.eval_dataset, desc="Evaluating"):
            input_ids = torch.tensor(example['input_ids']).unsqueeze(0).to(self.device)
            outputs = self.model.generate(input_ids, max_length=128)
            pred_answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            actual_answer = self.tokenizer.decode(example['labels'], skip_special_tokens=True)
            predictions.append(pred_answer)
            references.append(actual_answer)

        # Compute metrics
        results = rouge.compute(predictions=predictions, references=references)
        current_score = results['rouge1'].mid.fmeasure  # Using ROUGE-1 F1 score as the main evaluation metric

        print(f"Epoch {state.epoch}: ROUGE-1 F1 Score = {current_score}")

        # Save the epoch results to a text file
        with open("epoch_results.txt", "a") as f:
            f.write(f"Epoch {state.epoch}\n")
            for pred, ref in zip(predictions, references):
                f.write(f"Prediction: {pred}\n")
                f.write(f"Reference: {ref}\n\n")

        if current_score > self.best_score:
            self.best_score = current_score
            self.no_improvement_epochs = 0
            if os.path.exists(self.best_model_dir):
                shutil.rmtree(self.best_model_dir)
            os.makedirs(self.best_model_dir)
            self.model.save_pretrained(self.best_model_dir)
            self.tokenizer.save_pretrained(self.best_model_dir)
            with open(os.path.join(self.best_model_dir, 'eval_results.txt'), 'w') as f:
                f.write(f"ROUGE-1 F1 Score: {current_score}\n")
            print(f"New best model saved with ROUGE-1 F1 score: {self.best_score}")
        else:
            self.no_improvement_epochs += 1

        self.previous_score = current_score

        if self.no_improvement_epochs >= self.patience:
            print(f"Terminating training: No improvement observed for {self.patience} consecutive epochs.")
            control.should_training_stop = True

# Fine-tune on SQuAD 2.0
def fine_tune_on_squad():
    squad = load_dataset("squad_v2")
    tokenized_squad = squad.map(preprocess_data, batched=True, remove_columns=squad["train"].column_names)

    train_dataset = tokenized_squad["train"]
    eval_dataset = tokenized_squad["validation"]

    training_args = TrainingArguments(
        output_dir='./t5_squad',
        num_train_epochs=3,
        per_device_train_batch_size=8,
        gradient_accumulation_steps=2,
        warmup_steps=500,
        weight_decay=0.01,
        learning_rate=3e-5,
        logging_dir='./logs',
        logging_steps=100,
        save_strategy="epoch",
        evaluation_strategy="epoch",
        save_total_limit=2,
        fp16=torch.cuda.is_available(),
        report_to="none",
        load_best_model_at_end=True,
        metric_for_best_model="rouge1",
        greater_is_better=True,
    )

    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="pt", padding=True)
    trainer = Trainer(
        model=model,
        args=training_args,
        data_collator=data_collator,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        compute_metrics=lambda p: rouge.compute(predictions=[tokenizer.decode(pred, skip_special_tokens=True) for pred in p.predictions], references=[tokenizer.decode(label, skip_special_tokens=True) for label in p.label_ids]),
        callbacks=[SaveBestModelCallback(eval_dataset, tokenizer, model, device)]
    )

    trainer.train()
    model.save_pretrained("./t5_squad_finetuned")
    tokenizer.save_pretrained("./t5_squad_finetuned")

# Fine-tune on HotpotQA
def fine_tune_on_hotpotqa():
    hotpotqa = load_dataset("hotpotqa")
    tokenized_hotpotqa = hotpotqa.map(preprocess_data, batched=True, remove_columns=hotpotqa["train"].column_names)

    train_dataset = tokenized_hotpotqa["train"]
    eval_dataset = tokenized_hotpotqa["validation"]

    training_args = TrainingArguments(
        output_dir='./t5_hotpotqa',
        num_train_epochs=3,
        per_device_train_batch_size=8,
        gradient_accumulation_steps=2,
        warmup_steps=500,
        weight_decay=0.01,
        learning_rate=3e-5,
        logging_dir='./logs',
        logging_steps=100,
        save_strategy="epoch",
        evaluation_strategy="epoch",
        save_total_limit=2,
        fp16=torch.cuda.is_available(),
        report_to="none",
        load_best_model_at_end=True,
        metric_for_best_model="rouge1",
        greater_is_better=True,
    )

    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="pt", padding=True)
    trainer = Trainer(
        model=model,
        args=training_args,
        data_collator=data_collator,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        compute_metrics=lambda p: rouge.compute(predictions=[tokenizer.decode(pred, skip_special_tokens=True) for pred in p.predictions], references=[tokenizer.decode(label, skip_special_tokens=True) for label in p.label_ids]),
        callbacks=[SaveBestModelCallback(eval_dataset, tokenizer, model, device)]
    )

    trainer.train()
    model.save_pretrained("./t5_hotpotqa_finetuned")
    tokenizer.save_pretrained("./t5_hotpotqa_finetuned")

# Fine-tune on Natural Questions
def fine_tune_on_natural_questions():
    nq = load_dataset("natural_questions")
    tokenized_nq = nq.map(preprocess_data, batched=True, remove_columns=nq["train"].column_names)

    train_dataset = tokenized_nq["train"]
    eval_dataset = tokenized_nq["validation"]

    training_args = TrainingArguments(
        output_dir='./t5_nq',
        num_train_epochs=3,
        per_device_train_batch_size=8,
        gradient_accumulation_steps=2,
        warmup_steps=500,
        weight_decay=0.01,
        learning_rate=3e-5,
        logging_dir='./logs',
        logging_steps=100,
        save_strategy="epoch",
        evaluation_strategy="epoch",
        save_total_limit=2,
        fp16=torch.cuda.is_available(),
        report_to="none",
        load_best_model_at_end=True,
        metric_for_best_model="rouge1",
        greater_is_better=True,
    )

    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="pt", padding=True)
    trainer = Trainer(
        model=model,
        args=training_args,
        data_collator=data_collator,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        compute_metrics=lambda p: rouge.compute(predictions=[tokenizer.decode(pred, skip_special_tokens=True) for pred in p.predictions], references=[tokenizer.decode(label, skip_special_tokens=True) for label in p.label_ids]),
        callbacks=[SaveBestModelCallback(eval_dataset, tokenizer, model, device)]
    )

    trainer.train()
    model.save_pretrained("./t5_nq_finetuned")
    tokenizer.save_pretrained("./t5_nq_finetuned")

# Initialize the model and device
model = T5ForConditionalGeneration.from_pretrained(model_name)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Load evaluation metric
rouge = load_metric("rouge")

# Fine-tune sequentially on the selected datasets
fine_tune_on_squad()
model = T5ForConditionalGeneration.from_pretrained("./t5_squad_finetuned").to(device)
tokenizer = T5Tokenizer.from_pretrained("./t5_squad_finetuned")

fine_tune_on_hotpotqa()
model = T5ForConditionalGeneration.from_pretrained("./t5_hotpotqa_finetuned").to(device)
tokenizer = T5Tokenizer.from_pretrained("./t5_hotpotqa_finetuned")

fine_tune_on_natural_questions()
model = T5ForConditionalGeneration.from_pretrained("./t5_nq_finetuned").to(device)
tokenizer = T5Tokenizer.from_pretrained("./t5_nq_finetuned")

print("Model fine-tuning completed.")